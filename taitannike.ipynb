{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas #ipython notebook\n",
    "import numpy as np\n",
    "titanic = pandas.read_csv(\"titanic_train.csv\")\n",
    "titanic.head(5)\n",
    "#print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "2\n",
      "3\n",
      "891\n",
      "2\n",
      "89\n",
      "7\n",
      "7\n",
      "681\n",
      "248\n",
      "148\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for col in titanic.columns:\n",
    "    print(len(titanic[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId 0\n",
      "Survived 0\n",
      "Pclass 0\n",
      "Name 0\n",
      "Sex 0\n",
      "Age 177\n",
      "SibSp 0\n",
      "Parch 0\n",
      "Ticket 0\n",
      "Fare 0\n",
      "Cabin 687\n",
      "Embarked 2\n"
     ]
    }
   ],
   "source": [
    "for col in titanic.columns:\n",
    "    print(col,len(titanic[col][titanic[col].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print (titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of male with the number 0.\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print (titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train, test in kf.split(titanic):\n",
    "#     print(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "# kf = KFold(n_splits=3, random_state=1)\n",
    "kf = KFold(n_splits=3,shuffle=False, random_state=1)\n",
    "predictions = []\n",
    "for train, test in kf.split(titanic):\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 8.99877810e-02,  9.60756206e-01,  5.92676278e-01,  9.31138728e-01,\n",
       "         5.29343071e-02,  1.70275685e-01,  3.69943590e-01,  1.03474847e-01,\n",
       "         5.21597906e-01,  8.74491050e-01,  6.48883611e-01,  8.29742769e-01,\n",
       "         1.34797198e-01, -1.61126844e-01,  6.58141307e-01,  6.39819748e-01,\n",
       "         1.51733875e-01,  2.95432718e-01,  5.35377959e-01,  6.21007683e-01,\n",
       "         2.61872592e-01,  2.62687561e-01,  7.31739160e-01,  5.05995897e-01,\n",
       "         5.61398567e-01,  3.35039734e-01,  1.30338808e-01,  4.68765767e-01,\n",
       "         6.60737753e-01,  9.10819218e-02,  4.77223920e-01,  1.04220026e+00,\n",
       "         6.60691613e-01,  8.71539273e-02,  5.28550732e-01,  4.01874338e-01,\n",
       "         1.30340307e-01,  1.29339672e-01,  5.72717129e-01,  6.65238822e-01,\n",
       "         4.83215779e-01,  7.60807408e-01,  1.30578363e-01,  8.71867121e-01,\n",
       "         7.09855487e-01,  9.11369897e-02,  1.39181745e-01,  6.60691613e-01,\n",
       "         6.82833485e-02,  6.06254374e-01,  4.92254383e-02,  1.29250392e-01,\n",
       "         9.02668258e-01,  7.51677954e-01,  3.19636822e-01,  5.05995897e-01,\n",
       "         8.23411477e-01,  1.27611544e-01,  8.16516947e-01, -3.70209060e-02,\n",
       "         1.63085464e-01,  9.57981340e-01,  3.96742103e-01,  6.16138409e-02,\n",
       "         5.42714233e-01,  6.62112275e-02,  7.79751268e-01,  1.40293401e-01,\n",
       "         4.40592742e-01,  3.50534388e-02,  2.72709814e-01,  4.26360339e-01,\n",
       "         3.55241143e-01,  1.10226880e-01,  8.66078358e-02,  1.07366720e-01,\n",
       "         9.10819218e-02,  9.11369897e-02,  3.82661024e-01,  5.72471068e-01,\n",
       "         1.24221410e-01,  8.61972872e-02,  6.60705005e-01,  5.10138486e-01,\n",
       "         8.45241581e-01,  4.56477760e-01,  3.22699204e-02,  9.11369897e-02,\n",
       "         9.37604538e-01,  1.12967094e-01,  8.56794636e-02,  1.34727274e-01,\n",
       "         3.83320807e-01,  6.14970393e-03, -7.83320148e-02,  9.11369897e-02,\n",
       "         3.10516665e-01,  5.49345421e-01,  7.23544338e-01,  2.33721448e-01,\n",
       "         5.81750798e-01,  9.10819218e-02,  5.25738424e-01,  6.40651310e-02,\n",
       "        -2.52427240e-02,  9.10819218e-02,  6.19865700e-01,  9.10387818e-02,\n",
       "         3.65066610e-02,  6.32939707e-01,  4.08195377e-01,  6.63657306e-01,\n",
       "         1.23882146e-01,  5.92491292e-01,  6.83623624e-01,  1.29295032e-01,\n",
       "        -6.19221217e-02,  2.59223480e-01,  6.09655955e-01,  5.30794378e-01,\n",
       "         2.88023805e-01,  9.11369897e-02,  2.82857942e-01,  7.61542726e-01,\n",
       "         3.45640063e-01,  1.85484998e-01,  1.70022737e-01,  1.12642722e-01,\n",
       "         5.59420117e-01, -2.02485747e-03,  1.03290733e-01,  1.34440079e-01,\n",
       "         4.46807623e-01,  7.51677954e-01,  3.11805296e-01,  3.62947385e-01,\n",
       "         9.75724449e-01,  4.29554800e-01,  1.57043954e-01,  5.82928575e-01,\n",
       "         5.57105476e-01,  6.14443886e-01,  5.72812834e-01,  2.18783352e-01,\n",
       "         3.49472299e-01,  2.86040080e-01,  9.65037360e-02,  5.60916106e-01,\n",
       "         1.86919710e-01,  2.19027353e-01,  1.69739986e-01,  1.00690768e+00,\n",
       "        -5.89449777e-02, -4.15452572e-02,  9.08736139e-02,  3.95827915e-01,\n",
       "         7.26175962e-01,  8.02219375e-02,  9.13557255e-02, -2.22536096e-01,\n",
       "        -2.66919104e-02,  7.21593360e-01,  1.01953834e-01,  1.51388512e-01,\n",
       "         8.19705948e-02,  1.32518461e-01,  9.70245311e-01,  3.28974893e-01,\n",
       "         5.02576476e-01,  1.08437940e-01,  3.25183297e-01,  1.40818823e-01,\n",
       "         6.63268211e-01,  1.29295032e-01,  3.90965934e-01,  7.86503606e-02,\n",
       "        -3.68524682e-02,  9.13671691e-01,  2.84517666e-01,  4.46019673e-02,\n",
       "         2.68132779e-01,  3.35661255e-01,  1.96299597e-03,  3.51470400e-01,\n",
       "         6.51010647e-01,  5.11174133e-01,  6.29850621e-01,  4.10021732e-01,\n",
       "         4.03081359e-02,  4.74217131e-02,  7.64271489e-01,  3.44550453e-01,\n",
       "         5.97245007e-01,  3.69521460e-01,  9.46062691e-01,  9.12083149e-01,\n",
       "         1.70022737e-01, -1.85251802e-02,  6.60691613e-01,  8.07931698e-01,\n",
       "         9.16548133e-02, -2.22536096e-01,  5.78367977e-02,  3.48321010e-02,\n",
       "         1.45712251e-01,  6.91179799e-01,  3.84837497e-02,  1.45383056e-01,\n",
       "         7.26181926e-01,  4.78394987e-01,  1.12609974e-01,  7.50755869e-01,\n",
       "         1.23596450e-01,  2.84517666e-01,  1.36414068e-01,  1.01395495e+00,\n",
       "         5.87218752e-01,  1.90418359e-01,  1.02889863e+00,  2.83624866e-01,\n",
       "         1.56627303e-01,  3.00890244e-01, -3.43861103e-02,  9.10819218e-02,\n",
       "         4.37274991e-01,  1.24346402e-01,  3.43657653e-01,  1.31782740e-01,\n",
       "         3.50007979e-01,  4.53816408e-01,  9.41986239e-01,  8.55812557e-02,\n",
       "         1.26427969e-01,  5.14461976e-01,  3.16370023e-01,  5.81627306e-01,\n",
       "         1.79146187e-01,  8.33217359e-01,  3.43657653e-01,  2.67886176e-01,\n",
       "         5.89980704e-01,  6.29850621e-01,  2.89082393e-01,  1.23551810e-01,\n",
       "         1.19423755e-01,  4.49914049e-01,  5.98080236e-01,  7.41700785e-01,\n",
       "         3.95976588e-01,  1.24570927e-01,  9.08512939e-02,  5.10217925e-01,\n",
       "         3.17243789e-01,  4.94880818e-02,  4.48434902e-01,  5.51647950e-01,\n",
       "         1.05176735e+00,  1.00396283e+00,  1.16824364e+00,  6.37295280e-01,\n",
       "         1.70022737e-01,  3.47081525e-02,  3.23790141e-01,  4.27827834e-01,\n",
       "         6.60691613e-01,  2.50879710e-01,  1.07703504e-04,  7.38026906e-02,\n",
       "         8.41682429e-01,  9.94221666e-01,  5.04388858e-01,  1.04634754e-01,\n",
       "         6.84091736e-01,  4.60920013e-01,  6.60691613e-01,  7.87205387e-01,\n",
       "         4.88920786e-01,  2.90790162e-01,  1.24446245e-01,  4.80968077e-01,\n",
       "        -3.19057282e-02,  9.10670657e-02,  1.57145126e-01,  1.40254724e-01,\n",
       "         5.02603260e-01,  1.03564537e-01,  8.07397611e-02,  1.23827078e-01,\n",
       "         2.19027353e-01,  6.93436769e-01,  1.02306096e+00,  1.07151871e+00,\n",
       "         2.91224311e-01,  6.03921666e-01,  1.12912026e-01,  5.42714233e-01,\n",
       "         1.54899175e-01]),\n",
       " array([ 1.13774791,  0.44173212,  0.98551347,  0.66915371,  0.08254228,\n",
       "         0.15142624,  0.83642014,  0.09704526,  0.64711481,  1.03845173,\n",
       "         1.06064212,  0.24647842,  0.98364902,  1.04411609,  1.10195734,\n",
       "         0.72596387,  0.09692709,  0.11388411,  0.60824987,  0.74905725,\n",
       "         0.090424  ,  1.00314273,  0.91588368,  0.13679886,  0.10365487,\n",
       "         0.82296458,  0.755174  , -0.27746285,  1.0035964 , -0.12636043,\n",
       "         0.70865678,  0.52438799,  1.06900476,  0.58044138,  0.32246331,\n",
       "         0.45904751,  0.0848131 ,  0.96838383,  0.09692709,  0.4123739 ,\n",
       "         0.96908901, -0.01732698,  0.33119158,  0.38953146,  0.97455471,\n",
       "         0.26457991,  0.28476325,  0.21075768,  0.78939013,  0.68174567,\n",
       "         0.5508181 ,  0.21132238,  0.00332574,  0.1315846 ,  0.44518065,\n",
       "         0.16116388,  0.07440511,  0.13363265,  0.09815645,  0.98913539,\n",
       "         0.69520122,  0.66925272,  0.66925272, -0.05732283,  0.25605759,\n",
       "         0.51306171,  0.04918447,  0.12689844,  0.08297663,  0.74556032,\n",
       "         0.63153497,  0.66915371,  1.03349593,  0.46795359,  0.11283671,\n",
       "         0.15759527,  0.5998862 ,  0.6125967 ,  0.96615292,  0.63469796,\n",
       "         0.6051113 ,  0.18499302,  0.15738453,  1.03364995,  0.80043282,\n",
       "         0.07003835,  0.85871777,  0.09692709,  0.37822123,  0.03771546,\n",
       "         0.70865678,  0.17123866,  0.87293786,  0.38692632,  0.14394491,\n",
       "        -0.00364112,  1.02362819,  0.60920867,  0.13721713,  0.57461098,\n",
       "         0.1534423 ,  0.29630296,  0.76221079,  0.0229439 ,  0.11050082,\n",
       "         0.59310377,  0.05272741,  0.64923598,  0.18004866, -0.05792355,\n",
       "         0.37724772,  0.14392897,  0.44776777,  0.09692709,  0.17057126,\n",
       "         0.97573347,  0.2546175 , -0.01069499,  0.59494436,  0.67712284,\n",
       "         0.81048116,  0.25112435,  0.7091068 ,  0.13414671,  0.21833626,\n",
       "         0.09018337,  0.5398775 ,  0.11371054,  0.09643219,  0.72214613,\n",
       "         0.83299143,  0.1712546 ,  0.07013414,  0.43870508,  0.5508181 ,\n",
       "         0.62795723,  0.17034196,  0.26289071,  1.03283656,  0.54234647,\n",
       "         0.66429253,  0.2888594 ,  0.24248073,  0.59832765,  0.15197868,\n",
       "         0.06672256,  0.76247901,  0.09709316,  0.62328105,  0.85873908,\n",
       "         0.39833841,  0.68526385,  0.28026543,  0.15249025,  0.0558822 ,\n",
       "         0.46338875,  0.3322838 ,  0.09704526,  0.12741893,  0.18977726,\n",
       "         0.90570685,  0.61255203,  0.1712546 ,  0.3041495 ,  0.05667859,\n",
       "         0.32003504,  0.13002433,  0.09704526,  0.02900113,  0.2546175 ,\n",
       "         0.25032727,  0.17123545,  0.71385691,  0.09643219,  0.03023685,\n",
       "         0.67057269,  0.83394424,  0.63668087,  0.45820842,  0.18004866,\n",
       "         0.03925263,  0.13700639,  0.76347615, -0.01610677,  0.2546175 ,\n",
       "        -0.05096587,  0.36065035,  0.49526401,  0.44776777,  0.88783867,\n",
       "         0.27650531,  0.0835897 ,  0.17095571,  0.0558822 ,  0.14352664,\n",
       "         0.26008209,  0.20422092,  0.14413971,  0.13917582,  0.78823881,\n",
       "         0.10244795,  0.983009  ,  0.12376157,  0.17152021,  0.71624816,\n",
       "         0.66906113,  0.5355726 ,  1.06327957,  0.55601524,  0.71952689,\n",
       "         0.43870508,  0.10813802,  0.14762674,  0.16452683,  0.09704526,\n",
       "         0.38468169,  0.77378051,  0.12353167,  0.31660245,  0.72019649,\n",
       "         0.18382257,  0.6683239 ,  0.07001598,  0.97445504,  0.13729376,\n",
       "         0.13363265,  0.88062695,  0.13363587,  0.08715737,  0.61255203,\n",
       "         0.5883169 ,  0.0229439 ,  0.18684089,  0.88743056,  0.13363587,\n",
       "         0.14770832,  0.62385335,  0.58195819,  0.89464072,  0.32433284,\n",
       "         1.0215796 ,  0.10198815,  1.01250232,  0.89757009,  0.52011358,\n",
       "         0.50665802,  0.19733591,  0.33882963,  0.19608356,  0.78269614,\n",
       "         0.3024605 ,  0.01303333,  0.35740293,  0.59528255,  0.2812701 ,\n",
       "         0.1713153 ,  0.17399933,  0.63510029,  0.2099606 ,  0.79897366,\n",
       "         0.62993975,  0.84335812,  0.49799211,  0.1712546 ,  0.01619374,\n",
       "         0.26496308,  0.09704526,  0.59494436,  0.03570385,  0.1574771 ,\n",
       "         0.55964686,  0.13363587,  0.0699841 ,  0.03391958,  0.68692335,\n",
       "         0.38475832,  0.66915371,  0.17777861,  0.16253816,  0.72211234,\n",
       "         0.83479538,  0.58677963,  0.07003835,  0.735757  ,  0.90451305,\n",
       "         0.09962007,  0.43250553,  0.13477258,  1.02529894,  0.13828479,\n",
       "         0.24105043,  0.13741193,  0.09704526,  0.04924194,  0.80169436,\n",
       "        -0.03139561,  0.64987806]),\n",
       " array([ 1.72889219e-01,  1.70294715e-02,  7.82616935e-01, -8.34788848e-03,\n",
       "         1.47022266e-01,  3.10888595e-01,  7.28261340e-01,  1.01479914e-01,\n",
       "         4.24565622e-01,  1.57316587e-02,  4.37708069e-01,  1.44204264e-02,\n",
       "         9.07678482e-02,  4.33913871e-01,  8.26537251e-01,  8.45262338e-01,\n",
       "         5.42776171e-01,  1.01763663e-01,  6.70148479e-01,  1.92163452e-01,\n",
       "         6.39359534e-02,  7.62650655e-01,  3.10124701e-02,  5.90024631e-01,\n",
       "         8.31356231e-01,  2.78648916e-01,  1.08309653e-01,  3.04531238e-01,\n",
       "         1.50864127e-01,  1.38986099e-01,  1.36219795e-01,  2.51197915e-01,\n",
       "         2.02625887e-01,  9.72357134e-01,  1.12191979e-01,  1.92169054e-01,\n",
       "         1.50211875e-01, -2.14264992e-02,  4.52451020e-01,  4.38789988e-01,\n",
       "         6.04820088e-01,  7.89326541e-01,  8.00459867e-02,  2.10435721e-01,\n",
       "         5.70885269e-01,  5.70841743e-02,  1.44342132e-01,  1.00451104e+00,\n",
       "         6.42312317e-01,  8.51755703e-02,  7.33373007e-01,  3.09602117e-01,\n",
       "         1.49684208e-01,  3.22228832e-01,  1.01595923e-01,  6.50604478e-01,\n",
       "         1.01479914e-01,  8.45026241e-01,  1.38791822e-01,  7.14365273e-01,\n",
       "         7.68287651e-01,  1.84938938e-01,  1.01479914e-01,  6.54218524e-01,\n",
       "         2.93878313e-01,  2.96413137e-01,  1.92833539e-01,  8.27498735e-02,\n",
       "         3.28441263e-01,  5.87658439e-02,  1.02674988e-01,  1.42090676e-01,\n",
       "         2.83166248e-01,  1.01520440e-01,  2.10876914e-02,  9.01930011e-01,\n",
       "         6.80182444e-01,  3.63633521e-01,  4.29834748e-02,  2.51030051e-01,\n",
       "         2.71459394e-01,  1.55080767e-01,  1.20174297e-01,  6.76615822e-01,\n",
       "         5.21604336e-01,  2.74876851e-01,  7.14261845e-01,  4.63722197e-01,\n",
       "         1.43882255e-01, -3.38493769e-02,  5.08333972e-02,  2.88240761e-01,\n",
       "         4.71949096e-03,  1.48920991e-01,  1.55073789e-01,  9.65241409e-01,\n",
       "         3.61956120e-01,  8.01212426e-01,  8.51755703e-02,  1.63090365e-01,\n",
       "         2.58489938e-01,  1.38385623e-01,  1.57316587e-02,  7.14397446e-01,\n",
       "         2.98282232e-01,  2.65779163e-02,  9.41922468e-01,  3.92478820e-01,\n",
       "         7.25879907e-01,  2.08234335e-01,  7.05625434e-02,  2.03820545e-01,\n",
       "         6.98106244e-01,  3.54986591e-01,  9.42312534e-01,  1.08182230e-01,\n",
       "         1.01115214e+00,  4.29882986e-01,  2.72580965e-01,  9.55913060e-02,\n",
       "         1.38553363e-01,  1.49766670e-01,  8.76445205e-01,  7.95521275e-01,\n",
       "         1.89563479e-01,  7.47402760e-02,  9.05943831e-01,  1.19035222e-01,\n",
       "         2.34961953e-01,  1.49265429e-01,  3.84688624e-01,  1.44070963e-01,\n",
       "         6.51000458e-01,  7.14396037e-01,  2.37161612e-01,  5.98123216e-01,\n",
       "         8.84762775e-01,  2.34195832e-01,  2.71459394e-01,  2.93878313e-01,\n",
       "         2.93878313e-01,  9.60495497e-02,  4.82543535e-01,  2.74738708e-01,\n",
       "         1.01479914e-01,  1.01479914e-01,  4.28725578e-01,  3.27845711e-01,\n",
       "         8.83507841e-01,  7.85083053e-02,  8.54020195e-02,  1.53868294e-01,\n",
       "         1.25458500e-01,  7.78614476e-01,  4.27536886e-01,  1.76095354e-01,\n",
       "         8.78367308e-01,  2.23270579e-01,  7.41615725e-02,  1.28260077e-01,\n",
       "         6.34105869e-01,  3.76826088e-01,  1.01513462e-01,  3.21161697e-01,\n",
       "         6.92919862e-02,  9.05219168e-01,  9.92643346e-02,  3.21100762e-02,\n",
       "         1.89869119e-01,  8.47257439e-01,  1.65792833e-01,  7.70032759e-01,\n",
       "         4.70822280e-01,  7.01001762e-01,  1.45018183e-01,  7.98992141e-02,\n",
       "         1.22365867e-01, -5.62678525e-03,  6.34840292e-01,  1.47022266e-01,\n",
       "         6.21554022e-01,  1.55089154e-01,  1.92163452e-01,  7.45360827e-01,\n",
       "         1.92167645e-01,  8.15272492e-01,  7.49589740e-01,  9.59168970e-01,\n",
       "         4.23369546e-01,  6.56067455e-02,  1.17831761e-01,  1.17764665e-01,\n",
       "         6.77402825e-01,  1.31033823e-01,  2.11184136e-01,  3.61128670e-01,\n",
       "         1.92163452e-01,  3.27009298e-01,  2.80865752e-01,  4.73809464e-01,\n",
       "         1.17548012e-01,  2.08181789e-01,  8.39842956e-01,  6.07376016e-01,\n",
       "         1.36308792e-01,  5.71394060e-01,  2.34961953e-01,  7.32664113e-01,\n",
       "         4.58929866e-01,  2.99802486e-01,  1.07144857e-01,  8.54523415e-02,\n",
       "         3.79873628e-01,  6.77309159e-01,  2.08181789e-01,  8.74780819e-01,\n",
       "         1.12194764e-01,  3.71105893e-02,  2.30444621e-01,  5.78112549e-01,\n",
       "         8.80381008e-02,  4.38789988e-01,  6.50478673e-01,  2.52145211e-01,\n",
       "         2.16244600e-02,  7.72356638e-02,  7.64956968e-01,  1.06578734e-01,\n",
       "         3.85229660e-01,  6.33022282e-01,  6.89918839e-02,  1.92431836e-01,\n",
       "         8.51755703e-02,  4.59963761e-01,  1.92163452e-01,  7.52074841e-01,\n",
       "         6.94810438e-01,  3.74543331e-01,  1.47020857e-01,  1.28274033e-01,\n",
       "         1.54904640e-01,  8.83372143e-01,  1.38714930e-01,  1.01428183e-01,\n",
       "         6.37514393e-02,  4.74143535e-01,  1.44318380e-01,  3.32209243e-01,\n",
       "         9.85223737e-01,  1.12472244e-01,  1.60139061e-01,  2.66114644e-02,\n",
       "        -2.41362640e-01,  1.09304997e-01,  2.65882719e-01,  9.34799595e-01,\n",
       "         6.65962224e-02, -1.44857067e-01,  7.32175244e-01,  1.01756702e+00,\n",
       "         6.57625381e-01,  6.82274953e-01,  7.78507074e-01,  3.06694232e-01,\n",
       "         7.03120381e-01,  1.47020857e-01, -5.35194672e-02,  2.63450207e-01,\n",
       "         8.45198988e-01,  2.80865752e-01,  2.88522280e-01,  7.14342083e-01,\n",
       "         7.98068552e-01,  4.05781543e-01,  1.00941736e-01,  1.92789366e-01,\n",
       "         1.12191979e-01,  8.05473642e-01,  4.10332423e-01, -6.55145848e-04,\n",
       "         7.89310178e-01,  7.38879084e-01,  1.43673989e-01,  1.49684208e-01,\n",
       "         1.01479914e-01,  8.33962978e-01,  8.06527571e-01,  7.46997500e-02,\n",
       "         6.54965242e-01,  2.67936850e-01,  1.17831761e-01,  6.75775470e-01,\n",
       "         2.72454182e-01,  9.99158265e-01,  5.87835137e-01,  4.84754956e-01,\n",
       "         1.70739321e-01])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 8.99877810e-02,  9.60756206e-01,  5.92676278e-01,  9.31138728e-01,\n",
       "         5.29343071e-02,  1.70275685e-01,  3.69943590e-01,  1.03474847e-01,\n",
       "         5.21597906e-01,  8.74491050e-01,  6.48883611e-01,  8.29742769e-01,\n",
       "         1.34797198e-01, -1.61126844e-01,  6.58141307e-01,  6.39819748e-01,\n",
       "         1.51733875e-01,  2.95432718e-01,  5.35377959e-01,  6.21007683e-01,\n",
       "         2.61872592e-01,  2.62687561e-01,  7.31739160e-01,  5.05995897e-01,\n",
       "         5.61398567e-01,  3.35039734e-01,  1.30338808e-01,  4.68765767e-01,\n",
       "         6.60737753e-01,  9.10819218e-02,  4.77223920e-01,  1.04220026e+00,\n",
       "         6.60691613e-01,  8.71539273e-02,  5.28550732e-01,  4.01874338e-01,\n",
       "         1.30340307e-01,  1.29339672e-01,  5.72717129e-01,  6.65238822e-01,\n",
       "         4.83215779e-01,  7.60807408e-01,  1.30578363e-01,  8.71867121e-01,\n",
       "         7.09855487e-01,  9.11369897e-02,  1.39181745e-01,  6.60691613e-01,\n",
       "         6.82833485e-02,  6.06254374e-01,  4.92254383e-02,  1.29250392e-01,\n",
       "         9.02668258e-01,  7.51677954e-01,  3.19636822e-01,  5.05995897e-01,\n",
       "         8.23411477e-01,  1.27611544e-01,  8.16516947e-01, -3.70209060e-02,\n",
       "         1.63085464e-01,  9.57981340e-01,  3.96742103e-01,  6.16138409e-02,\n",
       "         5.42714233e-01,  6.62112275e-02,  7.79751268e-01,  1.40293401e-01,\n",
       "         4.40592742e-01,  3.50534388e-02,  2.72709814e-01,  4.26360339e-01,\n",
       "         3.55241143e-01,  1.10226880e-01,  8.66078358e-02,  1.07366720e-01,\n",
       "         9.10819218e-02,  9.11369897e-02,  3.82661024e-01,  5.72471068e-01,\n",
       "         1.24221410e-01,  8.61972872e-02,  6.60705005e-01,  5.10138486e-01,\n",
       "         8.45241581e-01,  4.56477760e-01,  3.22699204e-02,  9.11369897e-02,\n",
       "         9.37604538e-01,  1.12967094e-01,  8.56794636e-02,  1.34727274e-01,\n",
       "         3.83320807e-01,  6.14970393e-03, -7.83320148e-02,  9.11369897e-02,\n",
       "         3.10516665e-01,  5.49345421e-01,  7.23544338e-01,  2.33721448e-01,\n",
       "         5.81750798e-01,  9.10819218e-02,  5.25738424e-01,  6.40651310e-02,\n",
       "        -2.52427240e-02,  9.10819218e-02,  6.19865700e-01,  9.10387818e-02,\n",
       "         3.65066610e-02,  6.32939707e-01,  4.08195377e-01,  6.63657306e-01,\n",
       "         1.23882146e-01,  5.92491292e-01,  6.83623624e-01,  1.29295032e-01,\n",
       "        -6.19221217e-02,  2.59223480e-01,  6.09655955e-01,  5.30794378e-01,\n",
       "         2.88023805e-01,  9.11369897e-02,  2.82857942e-01,  7.61542726e-01,\n",
       "         3.45640063e-01,  1.85484998e-01,  1.70022737e-01,  1.12642722e-01,\n",
       "         5.59420117e-01, -2.02485747e-03,  1.03290733e-01,  1.34440079e-01,\n",
       "         4.46807623e-01,  7.51677954e-01,  3.11805296e-01,  3.62947385e-01,\n",
       "         9.75724449e-01,  4.29554800e-01,  1.57043954e-01,  5.82928575e-01,\n",
       "         5.57105476e-01,  6.14443886e-01,  5.72812834e-01,  2.18783352e-01,\n",
       "         3.49472299e-01,  2.86040080e-01,  9.65037360e-02,  5.60916106e-01,\n",
       "         1.86919710e-01,  2.19027353e-01,  1.69739986e-01,  1.00690768e+00,\n",
       "        -5.89449777e-02, -4.15452572e-02,  9.08736139e-02,  3.95827915e-01,\n",
       "         7.26175962e-01,  8.02219375e-02,  9.13557255e-02, -2.22536096e-01,\n",
       "        -2.66919104e-02,  7.21593360e-01,  1.01953834e-01,  1.51388512e-01,\n",
       "         8.19705948e-02,  1.32518461e-01,  9.70245311e-01,  3.28974893e-01,\n",
       "         5.02576476e-01,  1.08437940e-01,  3.25183297e-01,  1.40818823e-01,\n",
       "         6.63268211e-01,  1.29295032e-01,  3.90965934e-01,  7.86503606e-02,\n",
       "        -3.68524682e-02,  9.13671691e-01,  2.84517666e-01,  4.46019673e-02,\n",
       "         2.68132779e-01,  3.35661255e-01,  1.96299597e-03,  3.51470400e-01,\n",
       "         6.51010647e-01,  5.11174133e-01,  6.29850621e-01,  4.10021732e-01,\n",
       "         4.03081359e-02,  4.74217131e-02,  7.64271489e-01,  3.44550453e-01,\n",
       "         5.97245007e-01,  3.69521460e-01,  9.46062691e-01,  9.12083149e-01,\n",
       "         1.70022737e-01, -1.85251802e-02,  6.60691613e-01,  8.07931698e-01,\n",
       "         9.16548133e-02, -2.22536096e-01,  5.78367977e-02,  3.48321010e-02,\n",
       "         1.45712251e-01,  6.91179799e-01,  3.84837497e-02,  1.45383056e-01,\n",
       "         7.26181926e-01,  4.78394987e-01,  1.12609974e-01,  7.50755869e-01,\n",
       "         1.23596450e-01,  2.84517666e-01,  1.36414068e-01,  1.01395495e+00,\n",
       "         5.87218752e-01,  1.90418359e-01,  1.02889863e+00,  2.83624866e-01,\n",
       "         1.56627303e-01,  3.00890244e-01, -3.43861103e-02,  9.10819218e-02,\n",
       "         4.37274991e-01,  1.24346402e-01,  3.43657653e-01,  1.31782740e-01,\n",
       "         3.50007979e-01,  4.53816408e-01,  9.41986239e-01,  8.55812557e-02,\n",
       "         1.26427969e-01,  5.14461976e-01,  3.16370023e-01,  5.81627306e-01,\n",
       "         1.79146187e-01,  8.33217359e-01,  3.43657653e-01,  2.67886176e-01,\n",
       "         5.89980704e-01,  6.29850621e-01,  2.89082393e-01,  1.23551810e-01,\n",
       "         1.19423755e-01,  4.49914049e-01,  5.98080236e-01,  7.41700785e-01,\n",
       "         3.95976588e-01,  1.24570927e-01,  9.08512939e-02,  5.10217925e-01,\n",
       "         3.17243789e-01,  4.94880818e-02,  4.48434902e-01,  5.51647950e-01,\n",
       "         1.05176735e+00,  1.00396283e+00,  1.16824364e+00,  6.37295280e-01,\n",
       "         1.70022737e-01,  3.47081525e-02,  3.23790141e-01,  4.27827834e-01,\n",
       "         6.60691613e-01,  2.50879710e-01,  1.07703504e-04,  7.38026906e-02,\n",
       "         8.41682429e-01,  9.94221666e-01,  5.04388858e-01,  1.04634754e-01,\n",
       "         6.84091736e-01,  4.60920013e-01,  6.60691613e-01,  7.87205387e-01,\n",
       "         4.88920786e-01,  2.90790162e-01,  1.24446245e-01,  4.80968077e-01,\n",
       "        -3.19057282e-02,  9.10670657e-02,  1.57145126e-01,  1.40254724e-01,\n",
       "         5.02603260e-01,  1.03564537e-01,  8.07397611e-02,  1.23827078e-01,\n",
       "         2.19027353e-01,  6.93436769e-01,  1.02306096e+00,  1.07151871e+00,\n",
       "         2.91224311e-01,  6.03921666e-01,  1.12912026e-01,  5.42714233e-01,\n",
       "         1.54899175e-01]),\n",
       " array([ 1.13774791,  0.44173212,  0.98551347,  0.66915371,  0.08254228,\n",
       "         0.15142624,  0.83642014,  0.09704526,  0.64711481,  1.03845173,\n",
       "         1.06064212,  0.24647842,  0.98364902,  1.04411609,  1.10195734,\n",
       "         0.72596387,  0.09692709,  0.11388411,  0.60824987,  0.74905725,\n",
       "         0.090424  ,  1.00314273,  0.91588368,  0.13679886,  0.10365487,\n",
       "         0.82296458,  0.755174  , -0.27746285,  1.0035964 , -0.12636043,\n",
       "         0.70865678,  0.52438799,  1.06900476,  0.58044138,  0.32246331,\n",
       "         0.45904751,  0.0848131 ,  0.96838383,  0.09692709,  0.4123739 ,\n",
       "         0.96908901, -0.01732698,  0.33119158,  0.38953146,  0.97455471,\n",
       "         0.26457991,  0.28476325,  0.21075768,  0.78939013,  0.68174567,\n",
       "         0.5508181 ,  0.21132238,  0.00332574,  0.1315846 ,  0.44518065,\n",
       "         0.16116388,  0.07440511,  0.13363265,  0.09815645,  0.98913539,\n",
       "         0.69520122,  0.66925272,  0.66925272, -0.05732283,  0.25605759,\n",
       "         0.51306171,  0.04918447,  0.12689844,  0.08297663,  0.74556032,\n",
       "         0.63153497,  0.66915371,  1.03349593,  0.46795359,  0.11283671,\n",
       "         0.15759527,  0.5998862 ,  0.6125967 ,  0.96615292,  0.63469796,\n",
       "         0.6051113 ,  0.18499302,  0.15738453,  1.03364995,  0.80043282,\n",
       "         0.07003835,  0.85871777,  0.09692709,  0.37822123,  0.03771546,\n",
       "         0.70865678,  0.17123866,  0.87293786,  0.38692632,  0.14394491,\n",
       "        -0.00364112,  1.02362819,  0.60920867,  0.13721713,  0.57461098,\n",
       "         0.1534423 ,  0.29630296,  0.76221079,  0.0229439 ,  0.11050082,\n",
       "         0.59310377,  0.05272741,  0.64923598,  0.18004866, -0.05792355,\n",
       "         0.37724772,  0.14392897,  0.44776777,  0.09692709,  0.17057126,\n",
       "         0.97573347,  0.2546175 , -0.01069499,  0.59494436,  0.67712284,\n",
       "         0.81048116,  0.25112435,  0.7091068 ,  0.13414671,  0.21833626,\n",
       "         0.09018337,  0.5398775 ,  0.11371054,  0.09643219,  0.72214613,\n",
       "         0.83299143,  0.1712546 ,  0.07013414,  0.43870508,  0.5508181 ,\n",
       "         0.62795723,  0.17034196,  0.26289071,  1.03283656,  0.54234647,\n",
       "         0.66429253,  0.2888594 ,  0.24248073,  0.59832765,  0.15197868,\n",
       "         0.06672256,  0.76247901,  0.09709316,  0.62328105,  0.85873908,\n",
       "         0.39833841,  0.68526385,  0.28026543,  0.15249025,  0.0558822 ,\n",
       "         0.46338875,  0.3322838 ,  0.09704526,  0.12741893,  0.18977726,\n",
       "         0.90570685,  0.61255203,  0.1712546 ,  0.3041495 ,  0.05667859,\n",
       "         0.32003504,  0.13002433,  0.09704526,  0.02900113,  0.2546175 ,\n",
       "         0.25032727,  0.17123545,  0.71385691,  0.09643219,  0.03023685,\n",
       "         0.67057269,  0.83394424,  0.63668087,  0.45820842,  0.18004866,\n",
       "         0.03925263,  0.13700639,  0.76347615, -0.01610677,  0.2546175 ,\n",
       "        -0.05096587,  0.36065035,  0.49526401,  0.44776777,  0.88783867,\n",
       "         0.27650531,  0.0835897 ,  0.17095571,  0.0558822 ,  0.14352664,\n",
       "         0.26008209,  0.20422092,  0.14413971,  0.13917582,  0.78823881,\n",
       "         0.10244795,  0.983009  ,  0.12376157,  0.17152021,  0.71624816,\n",
       "         0.66906113,  0.5355726 ,  1.06327957,  0.55601524,  0.71952689,\n",
       "         0.43870508,  0.10813802,  0.14762674,  0.16452683,  0.09704526,\n",
       "         0.38468169,  0.77378051,  0.12353167,  0.31660245,  0.72019649,\n",
       "         0.18382257,  0.6683239 ,  0.07001598,  0.97445504,  0.13729376,\n",
       "         0.13363265,  0.88062695,  0.13363587,  0.08715737,  0.61255203,\n",
       "         0.5883169 ,  0.0229439 ,  0.18684089,  0.88743056,  0.13363587,\n",
       "         0.14770832,  0.62385335,  0.58195819,  0.89464072,  0.32433284,\n",
       "         1.0215796 ,  0.10198815,  1.01250232,  0.89757009,  0.52011358,\n",
       "         0.50665802,  0.19733591,  0.33882963,  0.19608356,  0.78269614,\n",
       "         0.3024605 ,  0.01303333,  0.35740293,  0.59528255,  0.2812701 ,\n",
       "         0.1713153 ,  0.17399933,  0.63510029,  0.2099606 ,  0.79897366,\n",
       "         0.62993975,  0.84335812,  0.49799211,  0.1712546 ,  0.01619374,\n",
       "         0.26496308,  0.09704526,  0.59494436,  0.03570385,  0.1574771 ,\n",
       "         0.55964686,  0.13363587,  0.0699841 ,  0.03391958,  0.68692335,\n",
       "         0.38475832,  0.66915371,  0.17777861,  0.16253816,  0.72211234,\n",
       "         0.83479538,  0.58677963,  0.07003835,  0.735757  ,  0.90451305,\n",
       "         0.09962007,  0.43250553,  0.13477258,  1.02529894,  0.13828479,\n",
       "         0.24105043,  0.13741193,  0.09704526,  0.04924194,  0.80169436,\n",
       "        -0.03139561,  0.64987806]),\n",
       " array([ 1.72889219e-01,  1.70294715e-02,  7.82616935e-01, -8.34788848e-03,\n",
       "         1.47022266e-01,  3.10888595e-01,  7.28261340e-01,  1.01479914e-01,\n",
       "         4.24565622e-01,  1.57316587e-02,  4.37708069e-01,  1.44204264e-02,\n",
       "         9.07678482e-02,  4.33913871e-01,  8.26537251e-01,  8.45262338e-01,\n",
       "         5.42776171e-01,  1.01763663e-01,  6.70148479e-01,  1.92163452e-01,\n",
       "         6.39359534e-02,  7.62650655e-01,  3.10124701e-02,  5.90024631e-01,\n",
       "         8.31356231e-01,  2.78648916e-01,  1.08309653e-01,  3.04531238e-01,\n",
       "         1.50864127e-01,  1.38986099e-01,  1.36219795e-01,  2.51197915e-01,\n",
       "         2.02625887e-01,  9.72357134e-01,  1.12191979e-01,  1.92169054e-01,\n",
       "         1.50211875e-01, -2.14264992e-02,  4.52451020e-01,  4.38789988e-01,\n",
       "         6.04820088e-01,  7.89326541e-01,  8.00459867e-02,  2.10435721e-01,\n",
       "         5.70885269e-01,  5.70841743e-02,  1.44342132e-01,  1.00451104e+00,\n",
       "         6.42312317e-01,  8.51755703e-02,  7.33373007e-01,  3.09602117e-01,\n",
       "         1.49684208e-01,  3.22228832e-01,  1.01595923e-01,  6.50604478e-01,\n",
       "         1.01479914e-01,  8.45026241e-01,  1.38791822e-01,  7.14365273e-01,\n",
       "         7.68287651e-01,  1.84938938e-01,  1.01479914e-01,  6.54218524e-01,\n",
       "         2.93878313e-01,  2.96413137e-01,  1.92833539e-01,  8.27498735e-02,\n",
       "         3.28441263e-01,  5.87658439e-02,  1.02674988e-01,  1.42090676e-01,\n",
       "         2.83166248e-01,  1.01520440e-01,  2.10876914e-02,  9.01930011e-01,\n",
       "         6.80182444e-01,  3.63633521e-01,  4.29834748e-02,  2.51030051e-01,\n",
       "         2.71459394e-01,  1.55080767e-01,  1.20174297e-01,  6.76615822e-01,\n",
       "         5.21604336e-01,  2.74876851e-01,  7.14261845e-01,  4.63722197e-01,\n",
       "         1.43882255e-01, -3.38493769e-02,  5.08333972e-02,  2.88240761e-01,\n",
       "         4.71949096e-03,  1.48920991e-01,  1.55073789e-01,  9.65241409e-01,\n",
       "         3.61956120e-01,  8.01212426e-01,  8.51755703e-02,  1.63090365e-01,\n",
       "         2.58489938e-01,  1.38385623e-01,  1.57316587e-02,  7.14397446e-01,\n",
       "         2.98282232e-01,  2.65779163e-02,  9.41922468e-01,  3.92478820e-01,\n",
       "         7.25879907e-01,  2.08234335e-01,  7.05625434e-02,  2.03820545e-01,\n",
       "         6.98106244e-01,  3.54986591e-01,  9.42312534e-01,  1.08182230e-01,\n",
       "         1.01115214e+00,  4.29882986e-01,  2.72580965e-01,  9.55913060e-02,\n",
       "         1.38553363e-01,  1.49766670e-01,  8.76445205e-01,  7.95521275e-01,\n",
       "         1.89563479e-01,  7.47402760e-02,  9.05943831e-01,  1.19035222e-01,\n",
       "         2.34961953e-01,  1.49265429e-01,  3.84688624e-01,  1.44070963e-01,\n",
       "         6.51000458e-01,  7.14396037e-01,  2.37161612e-01,  5.98123216e-01,\n",
       "         8.84762775e-01,  2.34195832e-01,  2.71459394e-01,  2.93878313e-01,\n",
       "         2.93878313e-01,  9.60495497e-02,  4.82543535e-01,  2.74738708e-01,\n",
       "         1.01479914e-01,  1.01479914e-01,  4.28725578e-01,  3.27845711e-01,\n",
       "         8.83507841e-01,  7.85083053e-02,  8.54020195e-02,  1.53868294e-01,\n",
       "         1.25458500e-01,  7.78614476e-01,  4.27536886e-01,  1.76095354e-01,\n",
       "         8.78367308e-01,  2.23270579e-01,  7.41615725e-02,  1.28260077e-01,\n",
       "         6.34105869e-01,  3.76826088e-01,  1.01513462e-01,  3.21161697e-01,\n",
       "         6.92919862e-02,  9.05219168e-01,  9.92643346e-02,  3.21100762e-02,\n",
       "         1.89869119e-01,  8.47257439e-01,  1.65792833e-01,  7.70032759e-01,\n",
       "         4.70822280e-01,  7.01001762e-01,  1.45018183e-01,  7.98992141e-02,\n",
       "         1.22365867e-01, -5.62678525e-03,  6.34840292e-01,  1.47022266e-01,\n",
       "         6.21554022e-01,  1.55089154e-01,  1.92163452e-01,  7.45360827e-01,\n",
       "         1.92167645e-01,  8.15272492e-01,  7.49589740e-01,  9.59168970e-01,\n",
       "         4.23369546e-01,  6.56067455e-02,  1.17831761e-01,  1.17764665e-01,\n",
       "         6.77402825e-01,  1.31033823e-01,  2.11184136e-01,  3.61128670e-01,\n",
       "         1.92163452e-01,  3.27009298e-01,  2.80865752e-01,  4.73809464e-01,\n",
       "         1.17548012e-01,  2.08181789e-01,  8.39842956e-01,  6.07376016e-01,\n",
       "         1.36308792e-01,  5.71394060e-01,  2.34961953e-01,  7.32664113e-01,\n",
       "         4.58929866e-01,  2.99802486e-01,  1.07144857e-01,  8.54523415e-02,\n",
       "         3.79873628e-01,  6.77309159e-01,  2.08181789e-01,  8.74780819e-01,\n",
       "         1.12194764e-01,  3.71105893e-02,  2.30444621e-01,  5.78112549e-01,\n",
       "         8.80381008e-02,  4.38789988e-01,  6.50478673e-01,  2.52145211e-01,\n",
       "         2.16244600e-02,  7.72356638e-02,  7.64956968e-01,  1.06578734e-01,\n",
       "         3.85229660e-01,  6.33022282e-01,  6.89918839e-02,  1.92431836e-01,\n",
       "         8.51755703e-02,  4.59963761e-01,  1.92163452e-01,  7.52074841e-01,\n",
       "         6.94810438e-01,  3.74543331e-01,  1.47020857e-01,  1.28274033e-01,\n",
       "         1.54904640e-01,  8.83372143e-01,  1.38714930e-01,  1.01428183e-01,\n",
       "         6.37514393e-02,  4.74143535e-01,  1.44318380e-01,  3.32209243e-01,\n",
       "         9.85223737e-01,  1.12472244e-01,  1.60139061e-01,  2.66114644e-02,\n",
       "        -2.41362640e-01,  1.09304997e-01,  2.65882719e-01,  9.34799595e-01,\n",
       "         6.65962224e-02, -1.44857067e-01,  7.32175244e-01,  1.01756702e+00,\n",
       "         6.57625381e-01,  6.82274953e-01,  7.78507074e-01,  3.06694232e-01,\n",
       "         7.03120381e-01,  1.47020857e-01, -5.35194672e-02,  2.63450207e-01,\n",
       "         8.45198988e-01,  2.80865752e-01,  2.88522280e-01,  7.14342083e-01,\n",
       "         7.98068552e-01,  4.05781543e-01,  1.00941736e-01,  1.92789366e-01,\n",
       "         1.12191979e-01,  8.05473642e-01,  4.10332423e-01, -6.55145848e-04,\n",
       "         7.89310178e-01,  7.38879084e-01,  1.43673989e-01,  1.49684208e-01,\n",
       "         1.01479914e-01,  8.33962978e-01,  8.06527571e-01,  7.46997500e-02,\n",
       "         6.54965242e-01,  2.67936850e-01,  1.17831761e-01,  6.75775470e-01,\n",
       "         2.72454182e-01,  9.99158265e-01,  5.87835137e-01,  4.84754956e-01,\n",
       "         1.70739321e-01])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833894500561167\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "# accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "accuracy = sum(predictions==titanic['Survived'])/len(predictions)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7957351290684623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=False, random_state=1)\n",
    "scores = cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=4, min_samples_leaf=2)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "kf = KFold(n_splits=3, shuffle=False, random_state=1)\n",
    "scores = cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征重要性衡量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面可以发现准确率有小幅提升，但是似乎得到的结果还是不太理想。我们可以发现模型似乎优化的差不多了，使用的特征似乎也已经使用完了。准确率已经达到了瓶颈，但是如果我们还想提高精度的话，还是要回到最原始的数据集里面。对分类器的结果最大的影响还是输入的数据本身。接下来采用的方法一般是从原始的数据集里面构造出新的特征。新增特征，家庭成员数和名字长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Mlle          2\n",
      "Col           2\n",
      "Mme           1\n",
      "Countess      1\n",
      "Ms            1\n",
      "Jonkheer      1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Don           1\n",
      "Lady          1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris   0  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina   1  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1   \n",
       "4                             Allen, Mr. William Henry   0  35.0      0   \n",
       "..                                                 ...  ..   ...    ...   \n",
       "886                              Montvila, Rev. Juozas   0  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith   1  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"   1  28.0      1   \n",
       "889                              Behr, Mr. Karl Howell   0  26.0      0   \n",
       "890                                Dooley, Mr. Patrick   0  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  FamilySize  NameLength  \\\n",
       "0        0         A/5 21171   7.2500   NaN        0           1          23   \n",
       "1        0          PC 17599  71.2833   C85        1           1          51   \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        0           0          22   \n",
       "3        0            113803  53.1000  C123        0           1          44   \n",
       "4        0            373450   8.0500   NaN        0           0          24   \n",
       "..     ...               ...      ...   ...      ...         ...         ...   \n",
       "886      0            211536  13.0000   NaN        0           0          21   \n",
       "887      0            112053  30.0000   B42        0           0          28   \n",
       "888      2        W./C. 6607  23.4500   NaN        0           3          40   \n",
       "889      0            111369  30.0000  C148        1           0          21   \n",
       "890      0            370376   7.7500   NaN        2           0          19   \n",
       "\n",
       "    Title  \n",
       "0       1  \n",
       "1       3  \n",
       "2       2  \n",
       "3       3  \n",
       "4       1  \n",
       "..    ...  \n",
       "886     6  \n",
       "887     2  \n",
       "888     2  \n",
       "889     1  \n",
       "890     1  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# import matplotlib.pyplot as plt\n",
    "# predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "\n",
    "# # Perform feature selection\n",
    "# selector = SelectKBest(f_classif, k=5)\n",
    "# selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# # Get the raw p-values for each feature, and transform from p-values into scores\n",
    "# scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# # Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "# plt.bar(range(len(predictors)), scores)\n",
    "# plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "# plt.show()\n",
    "\n",
    "# # Pick only the four best features.\n",
    "# predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "# alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    " \n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.\n",
    "    # Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Mlle          2\n",
      "Col           2\n",
      "Mme           1\n",
      "Countess      1\n",
      "Ms            1\n",
      "Jonkheer      1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Don           1\n",
      "Lady          1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\n",
    "    \"Mr\": 1,\n",
    "    \"Miss\": 2,\n",
    "    \"Mrs\": 3,\n",
    "    \"Master\": 4,\n",
    "    \"Dr\": 5,\n",
    "    \"Rev\": 6,\n",
    "    \"Major\": 7,\n",
    "    \"Col\": 7,\n",
    "    \"Mlle\": 8,\n",
    "    \"Mme\": 8,\n",
    "    \"Don\": 9,\n",
    "    \"Lady\": 10,\n",
    "    \"Countess\": 10,\n",
    "    \"Jonkheer\": 10,\n",
    "    \"Sir\": 9,\n",
    "    \"Capt\": 7,\n",
    "    \"Ms\": 2\n",
    "}\n",
    "for k, v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    " \n",
    "# Verify that we converted everything.\n",
    "# 验证我们是否转换了所有内容\n",
    "print(pandas.value_counts(titles))\n",
    " \n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif # 选择最好特征\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\n",
    "    \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\",\n",
    "    \"Title\", \"NameLength\"\n",
    "]\n",
    " \n",
    "# Perform feature selection\n",
    "# 执行特征选择\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    " \n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    " \n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    " \n",
    "# Pick only the four best features.\n",
    "# 只选择4个最好的特征\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    " \n",
    "alg = RandomForestClassifier(random_state=1,\n",
    "                             n_estimators=50,\n",
    "                             min_samples_split=8,\n",
    "                             min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pandas.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215488215488216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    " \n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\",]],\n",
    "    [LogisticRegression(random_state=1,solver='liblinear'), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    " \n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(n_splits=3,shuffle=False, random_state=1)\n",
    " \n",
    "predictions = []\n",
    "for train, test in kf.split(titanic):\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold. \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2  # 两个分类器的平均结果\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    " \n",
    "# Put all the predictions together into one array.\n",
    "# 将所有的预测放在一个数组中\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    " \n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions == titanic[\"Survived\"]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\n",
    "    \"Mr\": 1,\n",
    "    \"Miss\": 2,\n",
    "    \"Mrs\": 3,\n",
    "    \"Master\": 4,\n",
    "    \"Dr\": 5,\n",
    "    \"Rev\": 6,\n",
    "    \"Major\": 7,\n",
    "    \"Col\": 7,\n",
    "    \"Mlle\": 8,\n",
    "    \"Mme\": 8,\n",
    "    \"Don\": 9,\n",
    "    \"Lady\": 10,\n",
    "    \"Countess\": 10,\n",
    "    \"Jonkheer\": 10,\n",
    "    \"Sir\": 9,\n",
    "    \"Capt\": 7,\n",
    "    \"Ms\": 2,\n",
    "    \"Dona\": 10\n",
    "}\n",
    "for k, v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pandas.value_counts(titanic_test[\"Title\"]))\n",
    " \n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\n",
    "    \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"\n",
    "]\n",
    " \n",
    "algorithms = [\n",
    "    [\n",
    "        GradientBoostingClassifier(random_state=1,\n",
    "                                   n_estimators=25,\n",
    "                                   max_depth=3), predictors\n",
    "    ],\n",
    "    [\n",
    "        LogisticRegression(random_state=1, solver='liblinear'),\n",
    "        [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]\n",
    "    ]\n",
    "]\n",
    " \n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(\n",
    "        titanic_test[predictors].astype(float))[:, 1]\n",
    "    predictions[predictions <= .5] = 0\n",
    "    predictions[predictions > .5] = 1\n",
    "    full_predictions.append(predictions)\n",
    " \n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "# predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.11608616, 0.47313163, 0.12527406, 0.1305029 , 0.52004311,\n",
       "       0.14392415, 0.63984341, 0.18138299, 0.6778233 , 0.12095368,\n",
       "       0.12054308, 0.21154493, 0.91148439, 0.10814111, 0.89180609,\n",
       "       0.87818912, 0.1650196 , 0.13910405, 0.53990168, 0.551889  ,\n",
       "       0.22474624, 0.53695164, 0.90686439, 0.39533671, 0.88099058,\n",
       "       0.10288684, 0.9105501 , 0.13737153, 0.31376951, 0.12631623,\n",
       "       0.11615631, 0.18430576, 0.54919197, 0.49415142, 0.42910391,\n",
       "       0.14215743, 0.50825223, 0.52417057, 0.13230705, 0.28222509,\n",
       "       0.11076129, 0.47224517, 0.09914069, 0.83492474, 0.90028243,\n",
       "       0.14946376, 0.31905677, 0.1375202 , 0.89021873, 0.53830769,\n",
       "       0.36218205, 0.17945767, 0.83411368, 0.87864985, 0.17768223,\n",
       "       0.13743949, 0.10594413, 0.12307288, 0.12054944, 0.912131  ,\n",
       "       0.13115382, 0.15454243, 0.13002401, 0.66586834, 0.66161484,\n",
       "       0.87338585, 0.67298304, 0.29010609, 0.35826283, 0.84875193,\n",
       "       0.6621158 , 0.12688447, 0.55224753, 0.37379733, 0.91064833,\n",
       "       0.40981952, 0.12962877, 0.83764819, 0.15754935, 0.6621158 ,\n",
       "       0.68151841, 0.199957  , 0.20583641, 0.12054308, 0.1876183 ,\n",
       "       0.13090738, 0.65624963, 0.53041797, 0.6541947 , 0.80328565,\n",
       "       0.53643959, 0.12053355, 0.89344775, 0.12962877, 0.29113646,\n",
       "       0.12308551, 0.86391073, 0.14611431, 0.58582725, 0.12192637,\n",
       "       0.90507833, 0.1487208 , 0.1375202 , 0.1222069 , 0.62296229,\n",
       "       0.13079695, 0.1462909 , 0.1375202 , 0.12968111, 0.17805572,\n",
       "       0.14320048, 0.65420051, 0.89686624, 0.67202899, 0.87958304,\n",
       "       0.14013126, 0.11761531, 0.69866896, 0.369716  , 0.86312987,\n",
       "       0.87861506, 0.12587932, 0.90367706, 0.12049219, 0.1375202 ,\n",
       "       0.56989533, 0.12588394, 0.63632567, 0.13347645, 0.13308618,\n",
       "       0.12658342, 0.51402225, 0.23707771, 0.10764469, 0.09812515,\n",
       "       0.12399516, 0.13310033, 0.16414568, 0.51965018, 0.12217545,\n",
       "       0.20839696, 0.905255  , 0.19234654, 0.16288954, 0.43252003,\n",
       "       0.10460664, 0.34145835, 0.1349816 , 0.47224517, 0.34281095,\n",
       "       0.9150228 , 0.13168701, 0.10605776, 0.48641364, 0.11240039,\n",
       "       0.12396799, 0.91030126, 0.57927986, 0.43252003, 0.51097235,\n",
       "       0.65419138, 0.57892305, 0.82284027, 0.12047252, 0.28604791,\n",
       "       0.58375961, 0.30315379, 0.14606114, 0.90355986, 0.52205389,\n",
       "       0.12051582, 0.13260088, 0.12396504, 0.13162456, 0.13180211,\n",
       "       0.87544577, 0.87770527, 0.29748826, 0.83379914, 0.85394535,\n",
       "       0.15754935, 0.33614481, 0.90334825, 0.1375202 , 0.91674517,\n",
       "       0.13621589, 0.85707224, 0.12265744, 0.14145929, 0.13585733,\n",
       "       0.13547124, 0.2615505 , 0.49879649, 0.12640651, 0.72288221,\n",
       "       0.1072762 , 0.85708385, 0.59003429, 0.16902874, 0.53774638,\n",
       "       0.64770495, 0.66407876, 0.6048431 , 0.87648409, 0.16545898,\n",
       "       0.26353344, 0.62898005, 0.16722597, 0.89151239, 0.12309417,\n",
       "       0.127611  , 0.12047645, 0.24831086, 0.79802557, 0.41149964,\n",
       "       0.30039786, 0.65422041, 0.21582703, 0.89844275, 0.12962877,\n",
       "       0.81556725, 0.13597309, 0.84397565, 0.12687469, 0.87848249,\n",
       "       0.59630913, 0.12492255, 0.6541947 , 0.11396013, 0.14478507,\n",
       "       0.25316202, 0.89445045, 0.11621755, 0.13753447, 0.34495661,\n",
       "       0.12790127, 0.19280511, 0.1403001 , 0.81278248, 0.8975778 ,\n",
       "       0.8764603 , 0.8246372 , 0.32985937, 0.12054243, 0.33097517,\n",
       "       0.28960309, 0.88001689, 0.16051699, 0.86312987, 0.58951613,\n",
       "       0.74977708, 0.15427546, 0.39857128, 0.13320041, 0.12632896,\n",
       "       0.12051582, 0.1375202 , 0.12962877, 0.83210887, 0.12687265,\n",
       "       0.10829711, 0.1268804 , 0.85114827, 0.65202653, 0.16804208,\n",
       "       0.12054308, 0.22527114, 0.12051582, 0.50825223, 0.14031173,\n",
       "       0.34621912, 0.1375202 , 0.91585286, 0.63242282, 0.13162416,\n",
       "       0.85927352, 0.16037479, 0.12507105, 0.14380903, 0.17086699,\n",
       "       0.51978253, 0.66306258, 0.6541947 , 0.64321196, 0.71428972,\n",
       "       0.10527009, 0.12049219, 0.36739267, 0.13162456, 0.12962877,\n",
       "       0.33858104, 0.59221078, 0.13162456, 0.50262011, 0.120044  ,\n",
       "       0.12221704, 0.78214546, 0.12631623, 0.33515934, 0.11974185,\n",
       "       0.11749083, 0.17758584, 0.12164696, 0.133141  , 0.6541947 ,\n",
       "       0.8211081 , 0.33592591, 0.67771416, 0.20869482, 0.42050239,\n",
       "       0.13919512, 0.13794091, 0.12051779, 0.61683764, 0.89999581,\n",
       "       0.67464103, 0.23647358, 0.1765905 , 0.1213635 , 0.18705969,\n",
       "       0.1222069 , 0.13464434, 0.16414568, 0.46045705, 0.90515213,\n",
       "       0.12485392, 0.86892053, 0.34709   , 0.14585039, 0.17320123,\n",
       "       0.81934824, 0.33252581, 0.13162416, 0.64291933, 0.12136688,\n",
       "       0.25679033, 0.15446923, 0.09326367, 0.21115849, 0.35136293,\n",
       "       0.17856622, 0.11747726, 0.14689857, 0.91334888, 0.33472757,\n",
       "       0.61877994, 0.16414568, 0.62126456, 0.16774844, 0.85266978,\n",
       "       0.89655915, 0.16545898, 0.24611915, 0.16006513, 0.70327315,\n",
       "       0.15827211, 0.85634043, 0.12054177, 0.1375202 , 0.56988285,\n",
       "       0.10391274, 0.87788259, 0.86962862, 0.1305029 , 0.92015643,\n",
       "       0.15582768, 0.1309077 , 0.53155834, 0.89622127, 0.17553662,\n",
       "       0.15585283, 0.90915277, 0.16579567, 0.13122589, 0.87592006,\n",
       "       0.90842303, 0.48844403, 0.17292445, 0.19909204, 0.13524414,\n",
       "       0.1375202 , 0.13987028, 0.5390601 , 0.5941846 , 0.16075476,\n",
       "       0.83407033, 0.12398808, 0.11946654, 0.14628145, 0.18797311,\n",
       "       0.38986125, 0.87810898, 0.56353165, 0.12784258, 0.1030095 ,\n",
       "       0.91276766, 0.14226138, 0.88795149, 0.12588196, 0.12914704,\n",
       "       0.90748673, 0.12667147, 0.91041256, 0.36696583, 0.30783741,\n",
       "       0.19327157, 0.15249874, 0.26395095, 0.65418889, 0.64831126,\n",
       "       0.6541947 , 0.90753918, 0.56786185, 0.12962877, 0.85998813,\n",
       "       0.10048191, 0.12962877, 0.41631829])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
